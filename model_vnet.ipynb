{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import DataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.0001\n",
    "batch_size = 2\n",
    "prefetch = 2\n",
    "num_epochs = 10\n",
    "num_gpus = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def input_fn():\n",
    "    # trainTransforms = [\n",
    "    #     DataGenerator.Normalization(),\n",
    "    #     DataGenerator.RandomCrop(),\n",
    "    #     DataGenerator.RandomNoise(prob),\n",
    "    #     DataGenerator.BSplineTransform(2, 15, prob),\n",
    "    #     DataGenerator.RandomTranslation(prob)\n",
    "    #     ]\n",
    "\n",
    "    trainTransforms = [\n",
    "        DataGenerator.Normalization(),\n",
    "        DataGenerator.BSplineTransform(2, 15, prob)\n",
    "        ]\n",
    "\n",
    "    TrainDataset = DataGenerator.DataGenerator(\n",
    "        data_dir='train-data',\n",
    "        transforms=trainTransforms,\n",
    "        train=True\n",
    "        )\n",
    "\n",
    "    trainDataset = TrainDataset.get_dataset()\n",
    "    trainDataset = trainDataset.shuffle(buffer_size=5)\n",
    "    trainDataset = trainDataset.batch(batch_size)\n",
    "    trainDataset = trainDataset.prefetch(prefetch)\n",
    "\n",
    "    iterator = tf.data.Iterator.from_structure(trainDataset.output_types, trainDataset.output_shapes)\n",
    "    features, labels = iterator.get_next()\n",
    "#     training_init_op = iterator.make_initializer(trainDataset)\n",
    "\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv3d(x, no_of_input_channels, no_of_filters, filter_size, strides, padding, name):\n",
    "    with tf.variable_scope(name) as scope:\n",
    "        filter_size.extend([no_of_input_channels, no_of_filters])\n",
    "        weights = tf.Variable(tf.truncated_normal(filter_size, stddev=0.05), name='weights')\n",
    "        biases = tf.Variable(tf.truncated_normal([no_of_filters]), name='biases')\n",
    "        conv = tf.nn.conv3d(x, weights, strides=strides, padding=padding, name=name)\n",
    "        conv += biases\n",
    "        \n",
    "        return conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def upsamp(x, no_of_kernels, name):\n",
    "    with tf.variable_scope(name) as scope:\n",
    "        return tf.layers.conv3d_transpose(x, no_of_kernels, [2,2,1], 2, padding='VALID', use_bias=True, reuse=tf.AUTO_REUSE)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prelu(x, scope=None):\n",
    "    with tf.variable_scope(name_or_scope=scope, default_name=\"prelu\", reuse=tf.AUTO_REUSE):\n",
    "        alpha = tf.get_variable(\"prelu\", shape=x.get_shape()[-1], dtype=_x.dtype, initializer=tf.constant_initializer(0.1))\n",
    "        return tf.maximum(0.0, x) + alpha * tf.minimum(0.0, x)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def graph_encoder(x):\n",
    "    \n",
    "    fine_grained_features = {}\n",
    "    \n",
    "    conv1 = conv3d(x,1,16,[5,5,5],[1,1,1,1,1],'SAME','Conv1')\n",
    "    conv1 = prelu(conv1,'prelu1')\n",
    "    \n",
    "    res1 = tf.add(x,conv1)\n",
    "    fine_grained_features['res1'] = res1\n",
    "    \n",
    "    down1 = conv3d(res1,16,32,[2,2,1],[1,2,2,2,1],'VALID','DownSampling1')\n",
    "    down1 = prelu(down1,'down_prelu1')\n",
    "    \n",
    "    conv2 = conv3d(down1,32,32,[5,5,5],[1,1,1,1,1],'SAME','Conv2')\n",
    "    conv2 = prelu(conv2,'prelu2')\n",
    "    \n",
    "    conv3 = conv3d(conv2,32,32,[5,5,5],[1,1,1,1,1],'SAME','Conv3')\n",
    "    conv3 = prelu(conv3,'prelu3')\n",
    "    \n",
    "    res2 = tf.add(down1,conv3)\n",
    "    fine_grained_features['res2'] = res2\n",
    "\n",
    "    down2 = conv3d(res2,32,64,[2,2,1],[1,2,2,2,1],'VALID','DownSampling2')\n",
    "    down2 = prelu(down2,'down_prelu2')\n",
    "    \n",
    "    conv4 = conv3d(down2,64,64,[5,5,5],[1,1,1,1,1],'SAME','Conv4')\n",
    "    conv4 = prelu(conv4,'prelu4')\n",
    "    \n",
    "    conv5 = conv3d(conv4,64,64,[5,5,5],[1,1,1,1,1],'SAME','Conv5')\n",
    "    conv5 = prelu(conv5,'prelu5')\n",
    "    \n",
    "    conv6 = conv3d(conv5,64,64,[5,5,5],[1,1,1,1,1],'SAME','Conv6')\n",
    "    conv6 = prelu(conv6,'prelu6')\n",
    "    \n",
    "    res3 = tf.add(down2,conv6)\n",
    "    fine_grained_features['res3'] = res3\n",
    "\n",
    "    down3 = conv3d(res3,64,128,[2,2,1],[1,2,2,2,1],'VALID','DownSampling3')\n",
    "    down3 = prelu(down3,'down_prelu3')\n",
    "    \n",
    "    conv7 = conv3d(down3,128,128,[5,5,5],[1,1,1,1,1],'SAME','Conv7')\n",
    "    conv7 = prelu(conv7,'prelu7')\n",
    "    \n",
    "    conv8 = conv3d(conv7,128,128,[5,5,5],[1,1,1,1,1],'SAME','Conv8')\n",
    "    conv8 = prelu(conv8,'prelu8')\n",
    "    \n",
    "    conv9 = conv3d(conv8,128,128,[5,5,5],[1,1,1,1,1],'SAME','Conv9')\n",
    "    conv9 = prelu(conv9,'prelu9')\n",
    "    \n",
    "    res4 = tf.add(down3,conv9)\n",
    "    fine_grained_features['res4'] = res4\n",
    "\n",
    "    down4 = conv3d(res4,128,256,[2,2,1],[1,2,2,2,1],'VALID','DownSampling4')\n",
    "    down4 = prelu(down4,'down_prelu4')\n",
    "    \n",
    "    conv10 = conv3d(down4,256,256,[5,5,5],[1,1,1,1,1],'SAME','Conv10')\n",
    "    conv10 = prelu(conv10,'prelu10')\n",
    "    \n",
    "    conv11 = conv3d(conv10,256,256,[5,5,5],[1,1,1,1,1],'SAME','Conv11')\n",
    "    conv11 = prelu(conv11,'prelu11')\n",
    "    \n",
    "    conv12 = conv3d(conv11,256,256,[5,5,5],[1,1,1,1,1],'SAME','Conv12')\n",
    "    conv12 = prelu(conv12,'prelu12')\n",
    "    \n",
    "    res5 = tf.add(down4,conv12)\n",
    "    fine_grained_features['res5'] = res5\n",
    "    \n",
    "    return fine_grained_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def graph_decoder(features, labels):\n",
    "    \n",
    "    inp = features['res5']\n",
    "    \n",
    "    upsamp1 = upsamp(inp,128,'Upsampling1')\n",
    "    upsamp1 = prelu(upsamp1,'prelu_upsamp1')\n",
    "    \n",
    "    concat1 = tf.concat([upsamp1,features['res4']],axis=4)\n",
    "    \n",
    "    conv13 = conv3d(concat1,256,256,[5,5,5],[1,1,1,1,1],'SAME','Conv13')\n",
    "    conv13 = prelu(conv13,'prelu13')\n",
    "    \n",
    "    conv14 = conv3d(conv13,256,256,[5,5,5],[1,1,1,1,1],'SAME','Conv14')\n",
    "    conv14 = prelu(conv14,'prelu14')\n",
    "    \n",
    "    conv15 = conv3d(conv14,256,256,[5,5,5],[1,1,1,1,1],'SAME','Conv15')\n",
    "    conv15 = prelu(conv15,'prelu15')\n",
    "    \n",
    "    res6 = tf.add(concat1,conv15)\n",
    "    \n",
    "    upsamp2 = upsamp(res6,64,'Upsampling2')\n",
    "    upsamp2 = prelu(upsamp2,'prelu_upsamp2')\n",
    "    \n",
    "    concat2 = tf.concat([upsamp2,features['res3']],axis=4)\n",
    "    \n",
    "    conv16 = conv3d(concat2,128,128,[5,5,5],[1,1,1,1,1],'SAME','Conv16')\n",
    "    conv16 = prelu(conv16,'prelu16')\n",
    "    \n",
    "    conv17 = conv3d(conv16,128,128,[5,5,5],[1,1,1,1,1],'SAME','Conv17')\n",
    "    conv17 = prelu(conv17,'prelu17')\n",
    "    \n",
    "    conv18 = conv3d(conv17,128,128,[5,5,5],[1,1,1,1,1],'SAME','Conv18')\n",
    "    conv18 = prelu(conv18,'prelu18')\n",
    "    \n",
    "    res7 = tf.add(concat2,conv18)\n",
    "    \n",
    "    upsamp3 = upsamp(res7,32,'Upsampling3')\n",
    "    upsamp3 = prelu(upsamp3,'prelu_upsamp3')\n",
    "    \n",
    "    concat3 = tf.concat([upsamp3,features['res2']],axis=4)\n",
    "    \n",
    "    conv19 = conv3d(concat3,64,64,[5,5,5],[1,1,1,1,1],'SAME','Conv19')\n",
    "    conv19 = prelu(conv19,'prelu19')\n",
    "    \n",
    "    conv20 = conv3d(conv19,64,64,[5,5,5],[1,1,1,1,1],'SAME','Conv20')\n",
    "    conv20 = prelu(conv20,'prelu20')\n",
    "    \n",
    "    res8 = tf.add(concat3,conv20)\n",
    "    \n",
    "    upsamp4 = upsamp(res8,16,'Upsampling4')\n",
    "    upsamp4 = prelu(upsamp4,'prelu_upsamp4')\n",
    "    \n",
    "    concat4 = tf.concat([upsamp4,features['res1']],axis=4)\n",
    "    \n",
    "    conv21 = conv3d(concat4,32,32,[5,5,5],[1,1,1,1,1],'SAME','Conv21')\n",
    "    conv21 = prelu(conv21,'prelu21')\n",
    "    \n",
    "    res9 = tf.add(concat4,conv21)\n",
    "    \n",
    "    conv22 = conv3d(res9,32,2,[1,1,1],[1,1,1,1,1],'SAME','Conv22')\n",
    "    conv22 = prelu(conv22,'prelu22')\n",
    "    \n",
    "    return conv22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_fn(features, labels, mode):\n",
    "    encoded = graph_encoder(features)\n",
    "    decoded = graph_decoder(encoded, labels)\n",
    "\n",
    "    predictions = {\n",
    "          \"classes\": tf.argmax(input=tf.reshape(decoded, [-1, 2]), axis=1),\n",
    "          \"probabilities\": tf.nn.softmax(tf.reshape(decoded, [-1, 2]), axis=1, name=\"softmax_tensor\")\n",
    "       }\n",
    "\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "\n",
    "    with tf.variable_scope('cost') as scope:\n",
    "        cost = tf.divide(tf.multiply(2.0,tf.reduce_sum(tf.multiply(decoded, labels))),\n",
    "                         tf.add(tf.reduce_sum(tf.square(decoded)), tf.reduce_sum(tf.square(labels))))    \n",
    "\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        with tf.variable_scope('optimizer') as scope:\n",
    "            opt = tf.train.AdamOptimizer(learning_rate).maximize(cost, global_step=tf.train.get_global_step())\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, loss=cost, train_op=opt)\n",
    "\n",
    "    eval_metric_ops = {\"accuracy\": tf.metrics.accuracy(labels=labels, predictions=predictions[\"classes\"])}\n",
    "\n",
    "    return tf.estimator.EstimatorSpec(mode=mode, loss=cost, eval_metric_ops=eval_metric_ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': 'tmp/', '_tf_random_seed': 0, '_save_summary_steps': 100, '_save_checkpoints_steps': 2, '_save_checkpoints_secs': None, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x1827b04f60>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "run_config = tf.estimator.RunConfig(\n",
    "  save_checkpoints_steps=2,\n",
    "  tf_random_seed=0,\n",
    "  model_dir='tmp/'\n",
    ")\n",
    "\n",
    "estimator = tf.estimator.Estimator(model_fn=model_fn, config=run_config)\n",
    "estimator.train(input_fn, steps=num_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = np.random.randint(0,10,(128,128,64)).astype(np.float32).reshape((1,128,128,64,1))\n",
    "c = np.random.randint(0,10,(128,128,64)).astype(np.float32).reshape((1,128,128,64,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b = None\n",
    "encoded = graph_encoder(a)\n",
    "decoded = graph_decoder(encoded,c)\n",
    "with tf.Session() as sess:\n",
    "    writer = tf.summary.FileWriter(\"output\", sess.graph)\n",
    "\n",
    "    sess.run( tf.global_variables_initializer())\n",
    "    b = sess.run(decoded['gradients'])\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'b' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-89e6c98d9288>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'b' is not defined"
     ]
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.estimator.TrainSpec()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
